{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/harikrishnanagarajan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/harikrishnanagarajan/Downloads/romney-tweets.csv'\n",
    "df = pd.read_csv(dataset_path, usecols= ['Anootated tweet', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Insidious!&lt;e&gt;Mitt Romney&lt;/e&gt;'s Bain Helped Phi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior &lt;e&gt;Romney&lt;/e&gt; Advisor Claims &lt;e&gt;Obama&lt;/...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.@WardBrenda @shortwave8669 @allanbourdius you...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;e&gt;Mitt Romney&lt;/e&gt; still doesn't &lt;a&gt;believe&lt;/a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;e&gt;Romney&lt;/e&gt;'s &lt;a&gt;tax plan&lt;/a&gt; deserves a 2nd...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hope &lt;e&gt;Romney&lt;/e&gt; debate prepped w/ the same ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Want to know how &lt;e&gt;Mitt Romney&lt;/e&gt; is going t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If &lt;e&gt;Romney&lt;/e&gt; wins the &lt;a&gt;presidential elec...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Presidential debate round 2: &lt;e&gt;Romney&lt;/e&gt; wan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Someone on the &lt;e&gt;mitt Romney&lt;/e&gt; &lt;a&gt;Facebook ...</td>\n",
       "      <td>!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Anootated tweet Class\n",
       "0  Insidious!<e>Mitt Romney</e>'s Bain Helped Phi...    -1\n",
       "1  Senior <e>Romney</e> Advisor Claims <e>Obama</...     2\n",
       "2  .@WardBrenda @shortwave8669 @allanbourdius you...    -1\n",
       "3  <e>Mitt Romney</e> still doesn't <a>believe</a...    -1\n",
       "4  <e>Romney</e>'s <a>tax plan</a> deserves a 2nd...    -1\n",
       "5  Hope <e>Romney</e> debate prepped w/ the same ...     1\n",
       "6  Want to know how <e>Mitt Romney</e> is going t...    -1\n",
       "7  If <e>Romney</e> wins the <a>presidential elec...    -1\n",
       "8  Presidential debate round 2: <e>Romney</e> wan...     2\n",
       "9  Someone on the <e>mitt Romney</e> <a>Facebook ...  !!!!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    # Remove link,user and special characters\n",
    "    tweet = str(tweet).replace('<e>','')\n",
    "    tweet = str(tweet).replace('</e>', '')\n",
    "    tweet = re.sub(TEXT_CLEANING_RE, ' ', str(tweet).lower()).strip()\n",
    "    \n",
    "    tokens = []\n",
    "    for token in tweet.split():\n",
    "        if token not in stop_words:\n",
    "            tokens.append(stemmer.stem(token))\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Anootated tweet'] = df['Anootated tweet'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(data):\n",
    "    data = np.asarray(data)\n",
    "    temp = np.zeros((len(data),3))\n",
    "    for i in range(len(temp)):\n",
    "        if data[i] == '1':\n",
    "            temp[i][0] = 1\n",
    "        elif data[i] == '0':\n",
    "            temp[i][1] = 1\n",
    "        elif data[i] == '2':\n",
    "            temp[i][2] = 1\n",
    "\n",
    "    return temp     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    temp = []\n",
    "    for i in x:\n",
    "        m = np.argmax(i)\n",
    "        if m == 0:\n",
    "            temp.append('1')\n",
    "        elif m == 1:\n",
    "            temp.append('0')\n",
    "        else:\n",
    "            temp.append('2')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset= ['Class', 'Anootated tweet'])\n",
    "df = df[df.Class != '2']\n",
    "df = df[df.Class != 'irrelevant']\n",
    "df = df[df.Class != 'irrevelant']\n",
    "df = df[df.Class != '!!!!']\n",
    "df = df.replace('-1', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hope romney debat prep w peopl last time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pleas mitt romney huffingtonpost honey boo boo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>women poll show truli vote romney want know tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good luck mittromney tonight alreadi vote noth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debat tonight go pointless know romney win debat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mitt romney alway worship father must hurt lea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hope debat goe well romney tonight first time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yanke send arod debat romney amp start barack ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bo come fight mitt simpli take advantag obviou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oh yeah rt fwwak romney pray babi jesu assault...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Anootated tweet Class\n",
       "0           hope romney debat prep w peopl last time     1\n",
       "1  pleas mitt romney huffingtonpost honey boo boo...     0\n",
       "2  women poll show truli vote romney want know tr...     0\n",
       "3  good luck mittromney tonight alreadi vote noth...     1\n",
       "4   debat tonight go pointless know romney win debat     1\n",
       "5  mitt romney alway worship father must hurt lea...     0\n",
       "6  hope debat goe well romney tonight first time ...     1\n",
       "7  yanke send arod debat romney amp start barack ...     0\n",
       "8  bo come fight mitt simpli take advantag obviou...     1\n",
       "9  oh yeah rt fwwak romney pray babi jesu assault...     0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis= 1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_size: 2344\n",
      "\n",
      "Test_size: 414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size= 0.15, random_state= 5) \n",
    "print('Train_size:', len(df_train))\n",
    "print('\\nTest_size:', len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the vocab: 4429\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train['Anootated tweet'])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Total words in the vocab:', vocab_size)\n",
    "\n",
    "SEQ_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train['Anootated tweet']), maxlen= SEQ_LENGTH, padding='post', truncating = 'pre')\n",
    "\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test['Anootated tweet']), maxlen= SEQ_LENGTH, padding='post', truncating = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (2344, 50)\n",
      "Shape of y_train: (2344, 3)\n",
      "Shape of x_test: (414, 50)\n",
      "Shape of y_test: (414, 3)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(oneHotEncode(df_train.Class))\n",
    "\n",
    "y_test = np.array(oneHotEncode(df_test.Class))\n",
    "\n",
    "print('Shape of x_train:', x_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of x_test:', x_test.shape)\n",
    "print('Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "\n",
    "with open('/Users/harikrishnanagarajan/Downloads/glove/glove.twitter.27B.200d.txt', 'r') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        \n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vectors = np.asarray(values[1:], \"float32\")\n",
    "        embedding_dict[word] = vectors\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    \n",
    "    if i < vocab_size:\n",
    "        \n",
    "        emb_vec = embedding_dict.get(word)\n",
    "        if emb_vec is not None:\n",
    "            \n",
    "            embedding_matrix[i] = emb_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1_value(y_true, y_pred): #taken from old keras source code\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM, Bidirectional, SimpleRNN, GRU\n",
    "from keras import utils\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 200)           1334800   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 150)               165600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 453       \n",
      "=================================================================\n",
      "Total params: 1,500,853\n",
      "Trainable params: 166,053\n",
      "Non-trainable params: 1,334,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, peoch, logs= {}):\n",
    "        if logs.get('val_f1_value') > 0.5875:\n",
    "            print(\"Ending Training\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callback = myCallback()\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 200, weights= [embedding_matrix], input_length= SEQ_LENGTH, trainable= False)\n",
    "\n",
    "\n",
    "model_LSTM = Sequential()\n",
    "\n",
    "model_LSTM.add(embedding_layer)\n",
    "model_LSTM.add(Bidirectional(LSTM(75, activation= 'tanh')))\n",
    "model_LSTM.add(Dropout(0.2))\n",
    "model_LSTM.add(Dense(3, activation= 'softmax'))\n",
    "\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4322 samples, validate on 481 samples\n",
      "Epoch 1/15\n",
      "4322/4322 [==============================] - 15s 4ms/step - loss: 0.9809 - f1_value: 0.4201 - val_loss: 0.9188 - val_f1_value: 0.4957\n",
      "Epoch 2/15\n",
      "4322/4322 [==============================] - 12s 3ms/step - loss: 0.9005 - f1_value: 0.5090 - val_loss: 0.8893 - val_f1_value: 0.5124\n",
      "Epoch 3/15\n",
      "4322/4322 [==============================] - 12s 3ms/step - loss: 0.8468 - f1_value: 0.5578 - val_loss: 0.8804 - val_f1_value: 0.5462\n",
      "Epoch 4/15\n",
      "4322/4322 [==============================] - 12s 3ms/step - loss: 0.8120 - f1_value: 0.5986 - val_loss: 0.8729 - val_f1_value: 0.5678\n",
      "Epoch 5/15\n",
      "4322/4322 [==============================] - 13s 3ms/step - loss: 0.7630 - f1_value: 0.6424 - val_loss: 0.8994 - val_f1_value: 0.5451\n",
      "Epoch 6/15\n",
      "4322/4322 [==============================] - 12s 3ms/step - loss: 0.7273 - f1_value: 0.6680 - val_loss: 0.9042 - val_f1_value: 0.5541\n",
      "Epoch 7/15\n",
      "4322/4322 [==============================] - 12s 3ms/step - loss: 0.6826 - f1_value: 0.7000 - val_loss: 0.9122 - val_f1_value: 0.5313\n",
      "Epoch 8/15\n",
      "4322/4322 [==============================] - 13s 3ms/step - loss: 0.6329 - f1_value: 0.7255 - val_loss: 0.9329 - val_f1_value: 0.5461\n",
      "Epoch 9/15\n",
      "4322/4322 [==============================] - 13s 3ms/step - loss: 0.5740 - f1_value: 0.7585 - val_loss: 0.9460 - val_f1_value: 0.5957\n",
      "Ending Training\n"
     ]
    }
   ],
   "source": [
    "opt = adam(learning_rate= 0.001)\n",
    "model_LSTM.compile(loss= 'categorical_crossentropy', optimizer= opt, metrics= [f1_value])\n",
    "\n",
    "history = model_LSTM.fit(x_train, y_train, epochs= 15, validation_split= 0.1, batch_size= 64, verbose= 1, callbacks= [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.save('BEST_MODEL_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = model_LSTM.predict(x_test)\n",
    "f1_list= np.round(f1_score(pred(y_test), pred(y_pred), average = None),3)\n",
    "accuracy = accuracy_score(pred(y_test), pred(y_pred))\n",
    "f1_dict = {'f1_pos': f1_list[0], 'f1_neu': f1_list[1], 'f1_neg': f1_list[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_pos': 0.356, 'f1_neu': 0.401, 'f1_neg': 0.673}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5459905660377359"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 50, 200)           1334800   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 150)               124200    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 453       \n",
      "=================================================================\n",
      "Total params: 1,459,453\n",
      "Trainable params: 124,653\n",
      "Non-trainable params: 1,334,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, peoch, logs= {}):\n",
    "        if logs.get('val_f1_value') > 0.60:\n",
    "            print(\"Ending Training\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callback = myCallback()\n",
    "embedding_layer = Embedding(vocab_size, 200, weights= [embedding_matrix], input_length= SEQ_LENGTH, trainable= False)\n",
    "\n",
    "\n",
    "model_GRU = Sequential()\n",
    "\n",
    "model_GRU.add(embedding_layer)\n",
    "model_GRU.add(Bidirectional(GRU(75, activation= 'tanh')))\n",
    "model_GRU.add(Dropout(0.2))\n",
    "model_GRU.add(Dense(3, activation= 'softmax'))\n",
    "\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4322 samples, validate on 481 samples\n",
      "Epoch 1/20\n",
      "4322/4322 [==============================] - 14s 3ms/step - loss: 0.9961 - f1_value: 0.3995 - val_loss: 0.9474 - val_f1_value: 0.4566\n",
      "Epoch 2/20\n",
      "4322/4322 [==============================] - 10s 2ms/step - loss: 0.9041 - f1_value: 0.5061 - val_loss: 0.8889 - val_f1_value: 0.5381\n",
      "Epoch 3/20\n",
      "4322/4322 [==============================] - 11s 2ms/step - loss: 0.8462 - f1_value: 0.5661 - val_loss: 0.9042 - val_f1_value: 0.5618\n",
      "Epoch 4/20\n",
      "4322/4322 [==============================] - 10s 2ms/step - loss: 0.7966 - f1_value: 0.6143 - val_loss: 0.8827 - val_f1_value: 0.5317\n",
      "Epoch 5/20\n",
      "4322/4322 [==============================] - 10s 2ms/step - loss: 0.7442 - f1_value: 0.6512 - val_loss: 0.9008 - val_f1_value: 0.5712\n",
      "Epoch 6/20\n",
      "4322/4322 [==============================] - 9s 2ms/step - loss: 0.6882 - f1_value: 0.6879 - val_loss: 0.8933 - val_f1_value: 0.5946\n",
      "Epoch 7/20\n",
      "4322/4322 [==============================] - 9s 2ms/step - loss: 0.6154 - f1_value: 0.7362 - val_loss: 0.9387 - val_f1_value: 0.5871\n",
      "Epoch 8/20\n",
      "4322/4322 [==============================] - 10s 2ms/step - loss: 0.5451 - f1_value: 0.7759 - val_loss: 1.0268 - val_f1_value: 0.5500\n",
      "Epoch 9/20\n",
      "4322/4322 [==============================] - 10s 2ms/step - loss: 0.4412 - f1_value: 0.8307 - val_loss: 1.1441 - val_f1_value: 0.6059\n",
      "Ending Training\n"
     ]
    }
   ],
   "source": [
    "opt2 = adam(learning_rate= 0.002)\n",
    "model_GRU.compile(loss= 'categorical_crossentropy', optimizer= opt2, metrics= [f1_value])\n",
    "\n",
    "history2 = model_GRU.fit(x_train, y_train, epochs= 20, validation_split= 0.1, verbose= 1, batch_size=128, callbacks= [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU.save('BEST_MODEL_LS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_GRU.predict(x_test)\n",
    "f1_list= np.round(f1_score(pred(y_test), pred(y_pred), average = None),3)\n",
    "accuracy = accuracy_score(pred(y_test), pred(y_pred))\n",
    "f1_dict = {'f1_pos': f1_list[0], 'f1_neu': f1_list[1], 'f1_neg': f1_list[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_pos': 0.436, 'f1_neu': 0.34, 'f1_neg': 0.656}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5389150943396226"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "loaded_model = keras.models.load_model('BEST_MODEL_GRU', custom_objects= {'f1_value': f1_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = loaded_model.predict(x_test)\n",
    "f1_list= np.round(f1_score(pred(y_test), pred(y_pred), average = None),3)\n",
    "accuracy = accuracy_score(pred(y_test), pred(y_pred))\n",
    "f1_dict = {'f1_pos': f1_list[0], 'f1_neu': f1_list[1], 'f1_neg': f1_list[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_pos': 0.441, 'f1_neu': 0.098, 'f1_neg': 0.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23671497584541062"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
